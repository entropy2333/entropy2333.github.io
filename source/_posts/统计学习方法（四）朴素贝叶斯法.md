---
title: 统计学习方法（四）朴素贝叶斯法
date: 2020-08-14 23:23:09
tags:
- 机器学习
- 贝叶斯
category: 统计学习方法
---

朴素贝叶斯法基于贝叶斯定理，对于训练集，首先根据特征条件假设联合概率分布，基于此，对给定的输入，利用贝叶斯定理求出后验概率最大的输出。

<!--more-->

## 4.1 朴素贝叶斯法的学习与分类

### 基本方法

先验概率分布
$$
P(Y=c_k), \quad k=1,2,...K \tag{4.1}
$$
条件概率分布
$$
P(X=x|Y=c_k) = P(X^{(1)}=x^{(1)},...,X^{(n)}=x^{(n)}|Y=c_k) \tag{4.2}
$$
基本假设是条件独立性
$$
\begin{align}
P(X=x|Y=c_k) &= P(X^{(1)}x^{(1)},...,X^{(n)}=x^{(n)}|Y=c_k) \\
&= \prod _{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k) \\
\end{align}
\tag{4.3}
$$
后验概率计算
$$
P(Y=c_k|X=x)=\frac {P(X=x|Y=c_k)P(Y=c_k)} {P(X=x)}= \frac {P(X=x|Y=c_k)P(Y=c_k)} {\sum_j P(X=x|Y=c_j)P(Y=c_j)} \tag{4.4}
$$
代入(4.3)即得
$$
\begin{align}
P(Y=c_k|X=x)= \frac {P(Y=c_k)\prod_{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k)} {\sum_j P(Y=c_j)\prod _{i=1}^nP(X^{(i)}=x^{(i)}|Y=c_j)} \tag{4.5}
\end{align}
$$
所以朴素贝叶斯分类器可表示为
$$
\begin{align}
y=f(x)&= \arg\max_{c_k}\frac {P(Y=c_k)\prod _{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k)} {\sum_j P(Y=c_j)\prod _{i=1}^nP(X^{(i)}=x^{(i)}|Y=c_j)} \\ 
&=\arg\max_{c_k}P(Y=c_k)\prod _{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k)
\end{align}
\tag{4.6}
$$

### 后验概率最大化

假设选择0-1损失函数，这时期望风险函数为
$$
\begin{align}
R_{exp}(f) &= E[L(Y,f(X))]\\
&= E_X\sum_{k=1}^K[L(c_k,f(X))]P(c_k|X)
\end{align}
$$
为最小化期望风险，只需对X=x逐个极小化
$$
\begin{align}
f(x) &= \arg\min_{y\in \cal Y}\sum_{k=1}^KL(c_k,y)P(c_k|X=x) \\
&= \arg\min_{y\in \cal Y}\sum_{k=1}^KP(y\neq c_k|X=x) \\
&= \arg\min_{y\in \cal Y}\sum_{k=1}^K(1-P(y= c_k|X=x)) \\
&= \arg\max_{y\in \cal Y}\sum_{k=1}^KP(y= c_k|X=x)
\end{align}
$$

## 4.2 朴素贝叶斯法的参数估计

### 极大似然估计

先验概率的极大似然估计是
$$
P(Y=c_k) = \frac{\sum_{i=1}^NI(y_i=c_k)}{N},\quad k=1,2,..,K \tag{4.7}
$$
条件概率的极大似然估计是
$$
P(X^{(j)}=a_{ji}|Y=c_k) = \frac{\sum_{i=1}^NI(x_i^{(j)}=a_{ji},y_i=c_k)}{\sum_{i=1}^NI(y_i=c_k)},\quad k=1,2,..,K \tag{4.8}
$$

### 朴素贝叶斯算法

- 计算先验概率及条件概率
$$
\begin{align}
&P(Y=c_k) = \frac{\sum_{i=1}^NI(y_i=c_k)}{N},\quad k=1,2,..,K \\
&P(X^{(j)}=a_{ji}|Y=c_k) = \frac{\sum_{i=1}^NI(x_i^{(j)}=a_{ji},y_i=c_k)}{\sum_{i=1}^NI(y_i=c_k)},\quad k=1,2,..,K \\
&j=1,2,...,n;\quad k=1,2,...,K
\end{align}
$$
- 对于给定实例，计算
$$
P(Y=c_k)\prod _{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k)
$$
- 确定实例x的类
$$
y=\arg\max_{c_k}P(Y=c_k)\prod _{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k)
$$

### 贝叶斯估计

极大似然估计可能会出现所要估计的概率值为0的情况，这时会影响后验概率的计算结果，使分类产生偏差。

条件概率的贝叶斯估计是
$$
P_\lambda(X^{(j)}=a_{ji}|Y=c_k) = \frac {\sum_{i=1}^NI(x_i^{(j)}=a_{ji},y_i=c_k)+\lambda}{\sum_{i=1}^NI(y_i=c_k)+S_j\lambda}, \quad \lambda\geq0 \tag{4.9}
$$
等价于在随机变量每个取值的频数上赋予一个正数，λ=0时即为极大似然估计，常取λ=1，称为拉普拉斯平滑。

显然有
$$
P_\lambda(X^{(j)}=a_{ji}|Y=c_k) > 0 \\
\sum_{l=1}^{S_j}P(X^{(j)}=a_{ji}|Y=c_k) = 1
$$
先验概率的贝叶斯估计是
$$
P_\lambda(Y=c_k) = \frac {\sum_{i=1}^NI(y_i=c_k)+\lambda}{N+K\lambda}, \quad \lambda\geq0 \tag{4.10}
$$

## Scikit-learn

```python
from sklearn.naive_bayes import GaussianNB
# from sklearn.naive_bayes import BernoulliNB, MultinomialNB

clf = GaussianNB()
clf.fit(X_train, y_train)

clf.score(X_test, y_test)

clf.predict([[4.4,  3.2,  1.3,  0.2]])
```

## 总结

给定先验分布，利用贝叶斯定理求出后验概率最大的类。

